{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terrain Classification - Combined User Data\n",
    "### Created by Keenan McConkey 2019.08.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "\n",
    "from datetime import datetime\n",
    "from decimal import Decimal\n",
    "\n",
    "import pymrmr\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Importing Preprocessed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a) - Functions for Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the terrains, placements, vectors, power-assistance, users in the study\n",
    "terrains = ['Concrete', 'Carpet', 'Linoleum', 'Asphalt', 'Sidewalk', 'Grass', 'Gravel']\n",
    "powers = ['Manual'] # TODO: Fix power PSD data and add back in\n",
    "placements_manual = ['Middle', 'Left', 'Right', 'Synthesis']\n",
    "placements_power = ['Middle']\n",
    "vectors = ['Features', 'FFTs', 'PSDLogs']\n",
    "users = ['Keenan', 'Kevin', 'Mahsa', 'Jamie']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b) - Import Processed Data from Each User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Combine data from labelled datasets into a single dataframe'''\n",
    "def combine_datasets(datasets):\n",
    "    return pd.concat(list(datasets.values()), ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'processed_data/new_setup/' \n",
    "\n",
    "# Nested dictionary of processed data:\n",
    "# - Power assistance type\n",
    "# -- Placement\n",
    "# --- Feature Vector\n",
    "# ---- User\n",
    "power_dict = {}\n",
    "\n",
    "# Create each nesting of the dictionary\n",
    "for power in powers:\n",
    "    placement_dict = {}\n",
    "    \n",
    "    # Power datasets only have middle placement (for now)\n",
    "    if power == 'Power':\n",
    "        placements = placements_power.copy()\n",
    "    else:\n",
    "        placements = placements_manual.copy()\n",
    "    \n",
    "    for placement in placements:\n",
    "        vector_dict = {}\n",
    "\n",
    "        for vector in vectors:\n",
    "            user_dict = {}\n",
    "\n",
    "            for user in users:\n",
    "                # File name based on above parameters\n",
    "                filename = power.lower() + '/' + placement + '_' + vector + '_Filt_' + user \n",
    "                if power == 'Power':\n",
    "                    filename += '_Power'\n",
    "                filename += '.csv'\n",
    "                \n",
    "                # Read data and update current user dictionary\n",
    "                data = pd.read_csv(path + filename)\n",
    "                user_dict.update({user: data})\n",
    "\n",
    "            # Combine users to form a new entry of user dictionary, save to .csv\n",
    "            # NaNs arise when you combine Synthesis feature vectors\n",
    "            combined_data = combine_datasets(user_dict).dropna(axis='columns')\n",
    "            user_dict.update({'All': combined_data})\n",
    "\n",
    "            vector_dict.update({vector: user_dict})\n",
    "        \n",
    "        # Create a dictionary of the combined feature vector for each user\n",
    "        combined_vector_user_dict = {}\n",
    "        \n",
    "        for user in user_dict.keys():\n",
    "            # Get all vectors for current user and pop label column\n",
    "            user_all_vectors = []\n",
    "            \n",
    "            for vector in vector_dict.values():\n",
    "                user_vector = vector[user].copy()\n",
    "                labels = user_vector.pop('Label') # All label columns should be the same\n",
    "                user_all_vectors.append(user_vector)\n",
    "            \n",
    "            # Combine vectors and add back label column\n",
    "            combined_vector = pd.concat(user_all_vectors, axis='columns')\n",
    "            combined_vector.insert(loc=0, column='Label', value=labels)\n",
    "            combined_vector_user_dict.update({user: combined_vector})\n",
    "        \n",
    "        # Add the combined feature vector to the vector dictionary\n",
    "        vector_dict.update({'Combined': combined_vector_user_dict})\n",
    "        \n",
    "        placement_dict.update({placement: vector_dict})\n",
    "    \n",
    "    power_dict.update({power: placement_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Mean X Accel Middle</th>\n",
       "      <th>Std Dev X Accel Middle</th>\n",
       "      <th>L2 Norm X Accel Middle</th>\n",
       "      <th>Autocorrelation X Accel Middle</th>\n",
       "      <th>Max X Accel Middle</th>\n",
       "      <th>Min X Accel Middle</th>\n",
       "      <th>Root Mean Squared X Accel Middle</th>\n",
       "      <th>Zero Crossing Rate X Accel Middle</th>\n",
       "      <th>Skew X Accel Middle</th>\n",
       "      <th>...</th>\n",
       "      <th>PSD 1.0 Hz X Gyro Middle</th>\n",
       "      <th>PSD 1.0 Hz Z Accel Middle</th>\n",
       "      <th>PSD 1.0 Hz Y Accel Middle</th>\n",
       "      <th>PSD 1.0 Hz X Accel Middle</th>\n",
       "      <th>PSD 0.0 Hz Z Gyro Middle</th>\n",
       "      <th>PSD 0.0 Hz Y Gyro Middle</th>\n",
       "      <th>PSD 0.0 Hz X Gyro Middle</th>\n",
       "      <th>PSD 0.0 Hz Z Accel Middle</th>\n",
       "      <th>PSD 0.0 Hz Y Accel Middle</th>\n",
       "      <th>PSD 0.0 Hz X Accel Middle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8012</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.048488</td>\n",
       "      <td>-0.146781</td>\n",
       "      <td>-0.224684</td>\n",
       "      <td>-0.293490</td>\n",
       "      <td>-0.369834</td>\n",
       "      <td>0.803903</td>\n",
       "      <td>-0.224684</td>\n",
       "      <td>0.410072</td>\n",
       "      <td>-0.295411</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.199153</td>\n",
       "      <td>-2.119317</td>\n",
       "      <td>-1.360919</td>\n",
       "      <td>-1.726940</td>\n",
       "      <td>-1.125372</td>\n",
       "      <td>-2.414256</td>\n",
       "      <td>-3.104088</td>\n",
       "      <td>-1.992795</td>\n",
       "      <td>-0.906233</td>\n",
       "      <td>-0.163503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8013</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.838211</td>\n",
       "      <td>-0.549810</td>\n",
       "      <td>-0.679571</td>\n",
       "      <td>-0.697007</td>\n",
       "      <td>-0.727631</td>\n",
       "      <td>0.649344</td>\n",
       "      <td>-0.679571</td>\n",
       "      <td>-1.279923</td>\n",
       "      <td>0.891646</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.854475</td>\n",
       "      <td>-1.476822</td>\n",
       "      <td>-1.801745</td>\n",
       "      <td>-0.448959</td>\n",
       "      <td>-1.699782</td>\n",
       "      <td>-2.961492</td>\n",
       "      <td>-2.498364</td>\n",
       "      <td>-1.379586</td>\n",
       "      <td>-1.488251</td>\n",
       "      <td>0.043019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8014</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.058510</td>\n",
       "      <td>-1.523523</td>\n",
       "      <td>-1.527153</td>\n",
       "      <td>-1.358674</td>\n",
       "      <td>-0.612425</td>\n",
       "      <td>0.753509</td>\n",
       "      <td>-1.527153</td>\n",
       "      <td>1.255070</td>\n",
       "      <td>0.353343</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.651156</td>\n",
       "      <td>-2.436379</td>\n",
       "      <td>-1.318068</td>\n",
       "      <td>-1.271694</td>\n",
       "      <td>-1.236619</td>\n",
       "      <td>-2.188757</td>\n",
       "      <td>-2.502940</td>\n",
       "      <td>-1.908180</td>\n",
       "      <td>-1.126076</td>\n",
       "      <td>-0.427966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8015</th>\n",
       "      <td>5</td>\n",
       "      <td>0.068267</td>\n",
       "      <td>1.145593</td>\n",
       "      <td>1.019167</td>\n",
       "      <td>0.982532</td>\n",
       "      <td>2.396203</td>\n",
       "      <td>-0.863990</td>\n",
       "      <td>1.019167</td>\n",
       "      <td>-0.434925</td>\n",
       "      <td>1.624021</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.348061</td>\n",
       "      <td>-2.113860</td>\n",
       "      <td>-2.132868</td>\n",
       "      <td>-0.466117</td>\n",
       "      <td>-1.621375</td>\n",
       "      <td>-2.014946</td>\n",
       "      <td>-3.373160</td>\n",
       "      <td>-2.914507</td>\n",
       "      <td>-1.887899</td>\n",
       "      <td>0.042225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8016</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.180351</td>\n",
       "      <td>-1.198178</td>\n",
       "      <td>-1.241871</td>\n",
       "      <td>-1.149074</td>\n",
       "      <td>-0.756011</td>\n",
       "      <td>1.430402</td>\n",
       "      <td>-1.241871</td>\n",
       "      <td>-0.857424</td>\n",
       "      <td>-0.327254</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.855377</td>\n",
       "      <td>-2.770625</td>\n",
       "      <td>-2.242923</td>\n",
       "      <td>-1.473848</td>\n",
       "      <td>-1.418449</td>\n",
       "      <td>-2.783864</td>\n",
       "      <td>-2.749813</td>\n",
       "      <td>-2.456584</td>\n",
       "      <td>-0.994285</td>\n",
       "      <td>-0.041851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 811 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label  Mean X Accel Middle  Std Dev X Accel Middle  \\\n",
       "8012      5            -0.048488               -0.146781   \n",
       "8013      5            -0.838211               -0.549810   \n",
       "8014      5            -0.058510               -1.523523   \n",
       "8015      5             0.068267                1.145593   \n",
       "8016      5            -0.180351               -1.198178   \n",
       "\n",
       "      L2 Norm X Accel Middle  Autocorrelation X Accel Middle  \\\n",
       "8012               -0.224684                       -0.293490   \n",
       "8013               -0.679571                       -0.697007   \n",
       "8014               -1.527153                       -1.358674   \n",
       "8015                1.019167                        0.982532   \n",
       "8016               -1.241871                       -1.149074   \n",
       "\n",
       "      Max X Accel Middle  Min X Accel Middle  \\\n",
       "8012           -0.369834            0.803903   \n",
       "8013           -0.727631            0.649344   \n",
       "8014           -0.612425            0.753509   \n",
       "8015            2.396203           -0.863990   \n",
       "8016           -0.756011            1.430402   \n",
       "\n",
       "      Root Mean Squared X Accel Middle  Zero Crossing Rate X Accel Middle  \\\n",
       "8012                         -0.224684                           0.410072   \n",
       "8013                         -0.679571                          -1.279923   \n",
       "8014                         -1.527153                           1.255070   \n",
       "8015                          1.019167                          -0.434925   \n",
       "8016                         -1.241871                          -0.857424   \n",
       "\n",
       "      Skew X Accel Middle  ...  PSD 1.0 Hz X Gyro Middle  \\\n",
       "8012            -0.295411  ...                 -3.199153   \n",
       "8013             0.891646  ...                 -2.854475   \n",
       "8014             0.353343  ...                 -2.651156   \n",
       "8015             1.624021  ...                 -3.348061   \n",
       "8016            -0.327254  ...                 -3.855377   \n",
       "\n",
       "      PSD 1.0 Hz Z Accel Middle  PSD 1.0 Hz Y Accel Middle  \\\n",
       "8012                  -2.119317                  -1.360919   \n",
       "8013                  -1.476822                  -1.801745   \n",
       "8014                  -2.436379                  -1.318068   \n",
       "8015                  -2.113860                  -2.132868   \n",
       "8016                  -2.770625                  -2.242923   \n",
       "\n",
       "      PSD 1.0 Hz X Accel Middle  PSD 0.0 Hz Z Gyro Middle  \\\n",
       "8012                  -1.726940                 -1.125372   \n",
       "8013                  -0.448959                 -1.699782   \n",
       "8014                  -1.271694                 -1.236619   \n",
       "8015                  -0.466117                 -1.621375   \n",
       "8016                  -1.473848                 -1.418449   \n",
       "\n",
       "      PSD 0.0 Hz Y Gyro Middle  PSD 0.0 Hz X Gyro Middle  \\\n",
       "8012                 -2.414256                 -3.104088   \n",
       "8013                 -2.961492                 -2.498364   \n",
       "8014                 -2.188757                 -2.502940   \n",
       "8015                 -2.014946                 -3.373160   \n",
       "8016                 -2.783864                 -2.749813   \n",
       "\n",
       "      PSD 0.0 Hz Z Accel Middle  PSD 0.0 Hz Y Accel Middle  \\\n",
       "8012                  -1.992795                  -0.906233   \n",
       "8013                  -1.379586                  -1.488251   \n",
       "8014                  -1.908180                  -1.126076   \n",
       "8015                  -2.914507                  -1.887899   \n",
       "8016                  -2.456584                  -0.994285   \n",
       "\n",
       "      PSD 0.0 Hz X Accel Middle  \n",
       "8012                  -0.163503  \n",
       "8013                   0.043019  \n",
       "8014                  -0.427966  \n",
       "8015                   0.042225  \n",
       "8016                  -0.041851  \n",
       "\n",
       "[5 rows x 811 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check some data\n",
    "power_dict['Manual']['Middle']['Combined']['All'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Power'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fdbd083ac385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check some data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpower_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Power'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Middle'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FFTs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'All'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'Power'"
     ]
    }
   ],
   "source": [
    "# Check some data\n",
    "power_dict['Power']['Middle']['FFTs']['All'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Feature Selection mRMR (minimum Redunancy Maximum Relevance)\n",
    "\n",
    "Try to find which features are most relevant, from all directions.\n",
    "\n",
    "Features can be transforms or extracted features.\n",
    "\n",
    "mRMR tries to find which features have the highest correlation to classified state and lowest correlation with other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a) - Middle Frame Placement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (i) - Manual Wheelchair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Manual']['Middle']['Features']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Manual']['Middle']['FFTs']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Manual']['Middle']['PSDLogs']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Manual']['Middle']['Combined']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (i) - Power Assist Wheelchair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Power']['Middle']['Features']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Power']['Middle']['FFTs']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pymrmr.mRMR(data=power_dict['Power']['Middle']['PSDLogs']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pymrmr.mRMR(data=power_dict['Power']['Middle']['Combined']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b) - Left Wheel Placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Manual']['Left']['Features']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Manual']['Left']['FFTs']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Manual']['Left']['PSDLogs']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Manual']['Left']['Combined']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c) - Right Wheel Placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Manual']['Right']['Features']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Manual']['Right']['FFTs']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Manual']['Right']['PSDLogs']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Manual']['Right']['Combined']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (d) - Synthesis \"Placement\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Manual']['Synthesis']['Features']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Manual']['Synthesis']['FFTs']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Manual']['Synthesis']['PSDLogs']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymrmr.mRMR(data=power_dict['Manual']['Synthesis']['Combined']['All'], method='MID', nfeats=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Combining Data from Each Placement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Training Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "'''Run train test k-fold times\n",
    "   Returns predicted labels for each K Fold Test'''\n",
    "\n",
    "def train_test_k_fold(combined_data, n_splits, model):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "    # Copy data\n",
    "    data = combined_data.copy()\n",
    "    \n",
    "    # Extract terrain labels\n",
    "    labels = data.pop('Label')\n",
    "\n",
    "    # Array of predicted labels for each k fold\n",
    "    predict_k_fold = []\n",
    "    test_k_fold = []\n",
    "\n",
    "    # Split into n splits\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train, test = data.loc[train_index], data.loc[test_index]\n",
    "        train_labels, test_labels = labels.loc[train_index], labels.loc[test_index]\n",
    "\n",
    "        # Train and test model\n",
    "        model.fit(train, train_labels)\n",
    "        predict_k_fold.append(model.predict(test))\n",
    "        test_k_fold.append(test_labels)\n",
    "\n",
    "    \n",
    "    return (test_k_fold, predict_k_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a) - Create Accuracy Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dictionary of classifiers\n",
    "classifiers = {'Naive Bayes': GaussianNB(),\n",
    "               'k Nearest': KNeighborsClassifier(),\n",
    "               'Decision Tree': DecisionTreeClassifier(), \n",
    "               'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "               'AdaBoost': AdaBoostClassifier(),\n",
    "               'Support Vector Machine': SVC(gamma='scale')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_accuracy_table(n_splits, power_type='Manual', user_name='All'):\n",
    "    # Dataframe table of accuracies for each classifier for each placement\n",
    "    vector_indices = [placement + ' ' + vector for placement in placements for vector in vectors]\n",
    "    accuracy_table = pd.DataFrame({'Vector': vector_indices})\n",
    "\n",
    "    # Calculate accuracy for each placement for each feature vector and classifier\n",
    "    for classifier_name, classifier in classifiers.items():\n",
    "        model = classifier\n",
    "\n",
    "        # Row dictionary for given model\n",
    "        rows = {}\n",
    "\n",
    "        # Add current axis and classifier to row dictionary\n",
    "        for placement in placements:\n",
    "            for vector in vectors:\n",
    "                index_name = placement + ' ' + vector\n",
    "\n",
    "                # Extract predicted and actual labels for requested user\n",
    "                actual, predict = train_test_k_fold(placement_dict[power_type][placement][vector][user_name], \n",
    "                                                    n_splits, model)\n",
    "\n",
    "                # Take mean accuracy of k fold testing\n",
    "                accuracies = []\n",
    "                for i in range(len(predict)):\n",
    "                    accuracies.append(accuracy_score(actual[i], predict[i]))\n",
    "                rows.update({index_name: np.mean(accuracies)})\n",
    "\n",
    "        # Update accuracy table with classifier column by mapping row names to indices\n",
    "        accuracy_table[classifier_name] = accuracy_table['Vector'].map(rows)\n",
    "    return accuracy_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create accuracy table for 5 splits\n",
    "accuracy_table = create_accuracy_table(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10 - Combining Feature Selection with Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a) - Compare Top Features to Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_top(top_features, n_top):\n",
    "    subset_top_features = {}\n",
    "    \n",
    "    for placement, features in top_features.items():\n",
    "        n_features = features[0:n_top - 1]\n",
    "        # Add label to ensure it remains with the data\n",
    "        if 'Label' not in n_features:\n",
    "            n_features.append('Label')\n",
    "        \n",
    "        subset_top_features.update({placement: n_features})\n",
    "        \n",
    "    return subset_top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_n_feats(combined, top_features):\n",
    "    n_feats_arr = np.arange(5, len(top_features['Middle']), 5)\n",
    "    accuracies = {'Middle': []}\n",
    "\n",
    "    # Train and test for each number of top features\n",
    "    for n_feat in n_feats_arr:\n",
    "        \n",
    "        combined_top = top_features_only(combined, subset_top(top_features, n_feat))\n",
    "        # Get k fold predict and actual labels for each vector\n",
    "        feature = train_test_k_fold(combined_top, 5, model)\n",
    "        \n",
    "        # Compare accuracies vs top features\n",
    "        for placement in test_feat_top[1].keys():\n",
    "            # Extract predict and actual\n",
    "            predict, actual = feature[placement]\n",
    "            \n",
    "            # Take mean accuracy of k fold testing\n",
    "            accuracy_k_fold = []\n",
    "            \n",
    "            for i in range(len(predict)):\n",
    "                accuracy_k_fold.append(accuracy_score(actual[i], predict[i]))\n",
    "            \n",
    "            accuracies[placement].append(np.mean(accuracy_k_fold))\n",
    "\n",
    "    return n_feats_arr, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 11 - Classification on Single Axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a) - Separate Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Get placement dictionary of combined data truncated to only include columns matching given tag'''\n",
    "def get_matching_columns(combined_data, column_match):\n",
    "    # New placement dictionary with only matching columns\n",
    "    combined_matching_data = {}\n",
    "    \n",
    "    for placement, placement_data in combined_data.items():\n",
    "        # Retrieve column names that match the given match parameter\n",
    "        matching_columns = [column for column in placement_data.columns if column_match in column]\n",
    "        matching_columns.append('Label')\n",
    "        combined_matching_data.update({placement: placement_data[matching_columns]})\n",
    "        \n",
    "    return combined_matching_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Separate combined dataframe into dictionary of axes columns'''\n",
    "def separate_combined(combined_data):\n",
    "    separated_data = {}\n",
    "    \n",
    "    for axes_column in data_columns:\n",
    "        separated_data.update({axes_column: get_matching_columns(combined_data, axes_column)})\n",
    "        \n",
    "    return separated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_separated = separate_combined(feat_combined)\n",
    "fft_separated = separate_combined(fft_combined)\n",
    "psd_log_separated = separate_combined(psd_log_combined)\n",
    "\n",
    "feat_separated['Z Accel']['Middle'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b) - Compute Accuracy Table for Single Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_axes_accuracy_table(n_splits):\n",
    "    # Dataframe table of accuracies for each classifier for each placement\n",
    "    vector_indices = [vector + ' ' + placement + ' ' + axis for axis in data_columns for placement in placements for vector in vector_names]\n",
    "    axes_accuracy_table = pd.DataFrame({'Vector': vector_indices})\n",
    "\n",
    "    # Calculate accuracy for each axes of each placement for each feature vector and classifier\n",
    "    for classifier_name, classifier in classifiers.items():\n",
    "        model = classifier\n",
    "\n",
    "        # Row dictionary for given model\n",
    "        rows = {}\n",
    "\n",
    "        for axis in data_columns:\n",
    "            # Get k fold predict and actual labels for each vector for current axis\n",
    "            feat  = train_test_k_fold(feat_separated[axis], n_splits, model)\n",
    "            fft = train_test_k_fold(fft_separated[axis], n_splits, model)\n",
    "            psd_log = train_test_k_fold(psd_log_separated[axis], n_splits, model)\n",
    "            vectors = (feat, fft, psd_log)\n",
    "\n",
    "            # Add current axis and classifier to row dictionary\n",
    "            for i, vector_name in enumerate(vector_names):\n",
    "                for placement in placements:\n",
    "                    index_name = vector_name + ' ' + placement + ' ' + axis\n",
    "\n",
    "                    # Extract predicted and actual labels\n",
    "                    predict, actual = vectors[i][placement]\n",
    "\n",
    "                    # Take mean accuracy of k fold testing\n",
    "                    accuracies = []\n",
    "                    for j in range(len(predict)):\n",
    "                        accuracies.append(accuracy_score(actual[j], predict[j]))\n",
    "                    rows.update({index_name: np.mean(accuracies)})\n",
    "\n",
    "            # Update accuracy table with classifier column by mapping row names to indices\n",
    "            axes_accuracy_table[classifier_name] = axes_accuracy_table['Vector'].map(rows)\n",
    "    \n",
    "    return axes_accuracy_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "axes_accuracy_table = create_axes_accuracy_table(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes_accuracy_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glossary\n",
    "\n",
    "`Dataset` - Batch of data recorded on one terrain type\n",
    "\n",
    "`Data Window` - Split up portion of a `Dataset`\n",
    "\n",
    "`Direction / Axes` - Linear acceleration or gyroscope in $x,y$ or $z$\n",
    "\n",
    "`Feature Vector` - Any feature of the data that can be used to classify terrain, e.g. Z Accel Mean, Y Accel FFT, etc\n",
    "\n",
    "`Extracted Feature Vector` - Features that aren't from transforms, e.g. Z Accel Min, Y Accel Autocorrelation, etc\n",
    "\n",
    "`Placement` - One of three IMU placements on the wheelchair, i.e. Middle, Left, or Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
