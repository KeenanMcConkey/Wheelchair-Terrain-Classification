{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Join acc and gyro data then export to csv'''\n",
    "def join_export(acc_frame, gyro_frame, export_name):\n",
    "    # Extract only the gyroscope data from the gyro dataframe\n",
    "    # This assumes the time components of each are aligned\n",
    "    join_frame = acc_frame.join(gyro_frame[['GYROSCOPE X (rad/s)', 'GYROSCOPE Y (rad/s)', 'GYROSCOPE Z (rad/s)']])\n",
    "    path = 'imu_data/' + export_name\n",
    "    join_frame.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e9d5640e7a0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Wheel'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mterrain\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mgyro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Gyro'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mterrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Acc'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mterrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mjoin_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgyro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'raw_datasets' is not defined"
     ]
    }
   ],
   "source": [
    "# Run on everything\n",
    "\n",
    "terrains = ['Concrete', 'Carpet', 'Linoleum']\n",
    "locations = ['left', 'right', 'Frame9250']\n",
    "\n",
    "for terrain in terrains:\n",
    "    for location in locations:\n",
    "        if (location == 'Frame9250'):\n",
    "            filename = 'FrameMiddle' + terrain + '.csv'\n",
    "        else:\n",
    "            filename = 'Wheel' + location.capitalize() + terrain + '.csv'\n",
    "        gyro = raw_datasets[location + 'Gyro' + terrain]\n",
    "        acc = raw_datasets[location + 'Acc' + terrain]\n",
    "        join_export(acc, gyro, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Attempting to calculate the angular velocity of the wheelchair using the rotational velocity of each wheel\n",
    "\n",
    "wheel_radius = 0.60 #m\n",
    "wheel_sep = 0.502 #m\n",
    "\n",
    "raw_datasets['CalculatedLinoleum'] = pd.DataFrame()\n",
    "\n",
    "raw_datasets['calculatedLinoleum']['YYYY-MO-DD HH-MI-SS_SSS'] = raw_datasets['leftGyroLinoleum']['YYYY-MO-DD HH-MI-SS_SSS']\n",
    "raw_datasets['calculatedLinoleum']['GYROSCOPE Z (rad/s)'] = raw_datasets['leftGyroLinoleum']['GYROSCOPE Z (rad/s)'] - raw_datasets['rightGyroLinoleum']['GYROSCOPE Z (rad/s)'] \n",
    "raw_datasets['calculatedLinoleum']['GYROSCOPE Z (rad/s)'] = raw_datasets['calculatedLinoleum']['GYROSCOPE Z (rad/s)'].apply(lambda x: x*(wheel_radius/wheel_sep))\n",
    "\n",
    "label_compare('calculatedLinoleum', 'Frame9250GyroLinoleum', 'GYROSCOPE Z (rad/s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert time received to time since start\n",
    "for label in ('Concrete', 'Carpet', 'Linoleum'):\n",
    "    for mount in ('WheelLeft', 'WheelRight'):\n",
    "        start = Decimal(raw_datasets[mount+label]['Time received in s'][0])\n",
    "        raw_datasets[mount+label]['Time received in s'] = raw_datasets[mount+label]['Time received in s'].apply(lambda x: float((Decimal(x) - start) * 1000))\n",
    "        raw_datasets[mount+label].rename(columns = {'Time received in s': 'Time since start in ms '}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize order of columns\n",
    "for label in raw_datasets.keys():\n",
    "    raw_datasets[label] = raw_datasets[label][get_columns(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export everything to CSV\n",
    "for label, dataset in raw_datasets.items():\n",
    "    dataset.to_csv('imu_data/'+label+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Compare time domain data from phones mounted in different locations'''\n",
    "def phone_compare(dirn, surface):\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(30, 10))\n",
    "    \n",
    "    # Use epoch times to align data\n",
    "    for mount in ('Left', 'Right', 'Middle'):\n",
    "        plt.plot(raw_datasets['Phone' + mount + surface]['Epoch Time'],\n",
    "                 raw_datasets['Phone' + mount + surface][dirn], label=mount)\n",
    "    \n",
    "    plt.xlabel('Epoch Time (s)')\n",
    "    plt.ylabel(dirn + ' on ' + surface)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert string format to epoch time (newer data only)\n",
    "    if any(s in dataset_label for s in ('Phone', 'Asphalt', 'Grass', 'Gravel', 'Sidewalk')):\n",
    "        dataset['Epoch Time'] = dataset['Epoch Time'].apply(datetime.strptime, \n",
    "                                                            args=(\"%Y-%m-%d %H:%M:%S:%f\",))\n",
    "        dataset['Epoch Time'] = dataset['Epoch Time'].apply(datetime.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to convert everything to a single pandas dataset\n",
    "def to_single_dataframe(datasets, feat_names):\n",
    "    # Create the columns of the array\n",
    "    \n",
    "    columns = ['Label']\n",
    "    for j in range(N_DATA_COL):\n",
    "        for name in feat_names:\n",
    "            columns.append(dataset_columns[j] + ' ' + name)\n",
    "    dataframe = pd.DataFrame(columns=columns, index=[])\n",
    "    \n",
    "    for i, dataset in enumerate(datasets):\n",
    "        set_dataframe = pd.DataFrame(columns)\n",
    "        \n",
    "        for j, direction in enumerate(dataset[1:]):\n",
    "            # Direction labelled columns\n",
    "            direction_columns = ['Label']\n",
    "            for name in feat_names:\n",
    "                direction_columns.append(dataset_columns[j] + ' ' + name)\n",
    "            \n",
    "            # Data directions into a single dataframe\n",
    "            direction.columns = direction_columns\n",
    "            set_dataframe = set_dataframe.append(direction)\n",
    "            \n",
    "        # Combine datasets into a single dataframe\n",
    "        dataframe.append(dataset)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'Add labels to a dataset'\n",
    "def insert_labels(datasets, windowed=False):\n",
    "    # Add to each dataframe of a dataset\n",
    "    for i, (label, dataset) in enumerate(datasets.items()):\n",
    "        # Either formatted in windows (transforms) or dict->dict (features)\n",
    "        if (windowed):\n",
    "            for window_df in dataset:\n",
    "                labels = [get_terrain(label) for _ in range(len(window_df))]\n",
    "                window_df.insert(0, 'Label', labels)\n",
    "                window_df.set_index('Label')\n",
    "        \n",
    "        else:\n",
    "            for dirn_label, dirn_df  in dataset.items():\n",
    "                labels = [get_terrain(label) for _ in range(len(dirn_df))]\n",
    "                dirn_df.insert(0, 'Label', labels)\n",
    "                dirn_df.set_index('Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Set indices of a dataframe depending on given label'''\n",
    "def set_indices(dataframe):\n",
    "    if 'Frequency' in dataframe.columns:\n",
    "        return dataframe.set_index('Frequency')\n",
    "    elif 'Epoch Time' in dataframe.columns:\n",
    "        return dataframe.set_index('Epoch Time')\n",
    "    else:\n",
    "        raise('Unknown dataframe columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Move frequency column to index'''\n",
    "def set_freq_indices(datasets):\n",
    "    for dataset in datasets.values():\n",
    "        for window in dataset:\n",
    "            window = window.set_index('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Get recording range for speed tests'''\n",
    "def get_range(label):\n",
    "    # Recording ranges for each sampled terrain\n",
    "    ranges = {'AsphaltSlow_':   (2400, 4800), 'AsphaltSlow2_':   (3400, 6200),\n",
    "              'AsphaltMedium_': (3000, 5600), 'AsphaltFast_':    (1600, 3600),\n",
    "              'ConcreteFast_':  (1700, 5400), 'ConcreteMedium_': (2400, 4800),\n",
    "              'ConcreteSlow_':  (4000, 6800),\n",
    "              'AsphaltPowerRemoteMedium_': (2000, 10000),\n",
    "              'AsphaltPowerRemoteFast_': (1400, 5600),\n",
    "              'ConcretePowerRemoteFast_': (1600, 5600),\n",
    "              'ConcretePowerRemoteFast2_': (1400, 5200),\n",
    "              'ConcretePowerRemoteMedium_': (4000, 14000)}\n",
    "\n",
    "    for range_label, (start, stop) in ranges.items():\n",
    "        if range_label in label:\n",
    "            return start, stop\n",
    "    \n",
    "    raise ValueError('Unknown label ' + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for label, dataset in datasets.items():\n",
    "    start, stop = get_range(label)\n",
    "    print(label + ' {}'.format(np.sqrt(np.mean(np.power(dataset[start:stop, 5], 2)))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
