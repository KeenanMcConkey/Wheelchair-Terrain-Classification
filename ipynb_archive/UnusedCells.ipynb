{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the update rate of the IMU is non deterministic and lower than the rate the phone samples it at, i.e. the phone receives a non-deterministic number of sequential identical measurements from the IMU when polling at approx 200 Hz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasheets of smartphone level IMUs suggest that IMU filters data before sending it to the phone, and that the cutoff frequency of this filtering is configurable and changes with update frequency.\n",
    "\n",
    "Based on the IMU update rate of about 20 ms, this cutoff frequency is already close to 40 Hz, so filtering is probably unnecessary. Its hard to be sure about actual values because this is configured by the phone manufacturer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Join acc and gyro data then export to csv'''\n",
    "def join_export(acc_frame, gyro_frame, export_name):\n",
    "    # Extract only the gyroscope data from the gyro dataframe\n",
    "    # This assumes the time components of each are aligned\n",
    "    join_frame = acc_frame.join(gyro_frame[['GYROSCOPE X (rad/s)', 'GYROSCOPE Y (rad/s)', 'GYROSCOPE Z (rad/s)']])\n",
    "    path = 'imu_data/' + export_name\n",
    "    join_frame.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run on everything\n",
    "\n",
    "terrains = ['Concrete', 'Carpet', 'Linoleum']\n",
    "locations = ['left', 'right', 'Frame9250']\n",
    "\n",
    "for terrain in terrains:\n",
    "    for location in locations:\n",
    "        if (location == 'Frame9250'):\n",
    "            filename = 'FrameMiddle' + terrain + '.csv'\n",
    "        else:\n",
    "            filename = 'Wheel' + location.capitalize() + terrain + '.csv'\n",
    "        gyro = raw_datasets[location + 'Gyro' + terrain]\n",
    "        acc = raw_datasets[location + 'Acc' + terrain]\n",
    "        join_export(acc, gyro, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Attempting to calculate the angular velocity of the wheelchair using the rotational velocity of each wheel\n",
    "\n",
    "wheel_radius = 0.60 #m\n",
    "wheel_sep = 0.502 #m\n",
    "\n",
    "raw_datasets['CalculatedLinoleum'] = pd.DataFrame()\n",
    "\n",
    "raw_datasets['calculatedLinoleum']['YYYY-MO-DD HH-MI-SS_SSS'] = raw_datasets['leftGyroLinoleum']['YYYY-MO-DD HH-MI-SS_SSS']\n",
    "raw_datasets['calculatedLinoleum']['GYROSCOPE Z (rad/s)'] = raw_datasets['leftGyroLinoleum']['GYROSCOPE Z (rad/s)'] - raw_datasets['rightGyroLinoleum']['GYROSCOPE Z (rad/s)'] \n",
    "raw_datasets['calculatedLinoleum']['GYROSCOPE Z (rad/s)'] = raw_datasets['calculatedLinoleum']['GYROSCOPE Z (rad/s)'].apply(lambda x: x*(wheel_radius/wheel_sep))\n",
    "\n",
    "label_compare('calculatedLinoleum', 'Frame9250GyroLinoleum', 'GYROSCOPE Z (rad/s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert time received to time since start\n",
    "for label in ('Concrete', 'Carpet', 'Linoleum'):\n",
    "    for mount in ('WheelLeft', 'WheelRight'):\n",
    "        start = Decimal(raw_datasets[mount+label]['Time received in s'][0])\n",
    "        raw_datasets[mount+label]['Time received in s'] = raw_datasets[mount+label]['Time received in s'].apply(lambda x: float((Decimal(x) - start) * 1000))\n",
    "        raw_datasets[mount+label].rename(columns = {'Time received in s': 'Time since start in ms '}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize order of columns\n",
    "for label in raw_datasets.keys():\n",
    "    raw_datasets[label] = raw_datasets[label][get_columns(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export everything to CSV\n",
    "for label, dataset in raw_datasets.items():\n",
    "    dataset.to_csv('imu_data/'+label+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Compare time domain data from phones mounted in different locations'''\n",
    "def phone_compare(dirn, surface):\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(30, 10))\n",
    "    \n",
    "    # Use epoch times to align data\n",
    "    for mount in ('Left', 'Right', 'Middle'):\n",
    "        plt.plot(raw_datasets['Phone' + mount + surface]['Epoch Time'],\n",
    "                 raw_datasets['Phone' + mount + surface][dirn], label=mount)\n",
    "    \n",
    "    plt.xlabel('Epoch Time (s)')\n",
    "    plt.ylabel(dirn + ' on ' + surface)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert string format to epoch time (newer data only)\n",
    "    if any(s in dataset_label for s in ('Phone', 'Asphalt', 'Grass', 'Gravel', 'Sidewalk')):\n",
    "        dataset['Epoch Time'] = dataset['Epoch Time'].apply(datetime.strptime, \n",
    "                                                            args=(\"%Y-%m-%d %H:%M:%S:%f\",))\n",
    "        dataset['Epoch Time'] = dataset['Epoch Time'].apply(datetime.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to convert everything to a single pandas dataset\n",
    "def to_single_dataframe(datasets, feat_names):\n",
    "    # Create the columns of the array\n",
    "    \n",
    "    columns = ['Label']\n",
    "    for j in range(N_DATA_COL):\n",
    "        for name in feat_names:\n",
    "            columns.append(dataset_columns[j] + ' ' + name)\n",
    "    dataframe = pd.DataFrame(columns=columns, index=[])\n",
    "    \n",
    "    for i, dataset in enumerate(datasets):\n",
    "        set_dataframe = pd.DataFrame(columns)\n",
    "        \n",
    "        for j, direction in enumerate(dataset[1:]):\n",
    "            # Direction labelled columns\n",
    "            direction_columns = ['Label']\n",
    "            for name in feat_names:\n",
    "                direction_columns.append(dataset_columns[j] + ' ' + name)\n",
    "            \n",
    "            # Data directions into a single dataframe\n",
    "            direction.columns = direction_columns\n",
    "            set_dataframe = set_dataframe.append(direction)\n",
    "            \n",
    "        # Combine datasets into a single dataframe\n",
    "        dataframe.append(dataset)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'Add labels to a dataset'\n",
    "def insert_labels(datasets, windowed=False):\n",
    "    # Add to each dataframe of a dataset\n",
    "    for i, (label, dataset) in enumerate(datasets.items()):\n",
    "        # Either formatted in windows (transforms) or dict->dict (features)\n",
    "        if (windowed):\n",
    "            for window_df in dataset:\n",
    "                labels = [get_terrain(label) for _ in range(len(window_df))]\n",
    "                window_df.insert(0, 'Label', labels)\n",
    "                window_df.set_index('Label')\n",
    "        \n",
    "        else:\n",
    "            for dirn_label, dirn_df  in dataset.items():\n",
    "                labels = [get_terrain(label) for _ in range(len(dirn_df))]\n",
    "                dirn_df.insert(0, 'Label', labels)\n",
    "                dirn_df.set_index('Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Set indices of a dataframe depending on given label'''\n",
    "def set_indices(dataframe):\n",
    "    if 'Frequency' in dataframe.columns:\n",
    "        return dataframe.set_index('Frequency')\n",
    "    elif 'Epoch Time' in dataframe.columns:\n",
    "        return dataframe.set_index('Epoch Time')\n",
    "    else:\n",
    "        raise('Unknown dataframe columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Move frequency column to index'''\n",
    "def set_freq_indices(datasets):\n",
    "    for dataset in datasets.values():\n",
    "        for window in dataset:\n",
    "            window = window.set_index('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Get recording range for speed tests'''\n",
    "def get_range(label):\n",
    "    # Recording ranges for each sampled terrain\n",
    "    ranges = {'AsphaltSlow_':   (2400, 4800), 'AsphaltSlow2_':   (3400, 6200),\n",
    "              'AsphaltMedium_': (3000, 5600), 'AsphaltFast_':    (1600, 3600),\n",
    "              'ConcreteFast_':  (1700, 5400), 'ConcreteMedium_': (2400, 4800),\n",
    "              'ConcreteSlow_':  (4000, 6800),\n",
    "              'AsphaltPowerRemoteMedium_': (2000, 10000),\n",
    "              'AsphaltPowerRemoteFast_': (1400, 5600),\n",
    "              'ConcretePowerRemoteFast_': (1600, 5600),\n",
    "              'ConcretePowerRemoteFast2_': (1400, 5200),\n",
    "              'ConcretePowerRemoteMedium_': (4000, 14000)}\n",
    "\n",
    "    for range_label, (start, stop) in ranges.items():\n",
    "        if range_label in label:\n",
    "            return start, stop\n",
    "    \n",
    "    raise ValueError('Unknown label ' + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for label, dataset in datasets.items():\n",
    "    start, stop = get_range(label)\n",
    "    print(label + ' {}'.format(np.sqrt(np.mean(np.power(dataset[start:stop, 5], 2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine all data individually\n",
    "# TODO: Combine each direction of a single dataset into a single dataframe so we can select across \n",
    "datasets_middle = {label: dataset for label, dataset in datasets_psd_log_combined.items() if 'Middle' in label}\n",
    "datasets_left = {label: dataset for label, dataset in datasets_psd_log_combined.items() if 'Left' in label}\n",
    "datasets_right = {label: dataset for label, dataset in datasets_psd_log_combined.items() if 'Right' in label}\n",
    "\n",
    "middle_psd_logs_all = combine_datasets(datasets_middle)\n",
    "left_psd_logs_all = combine_datasets(datasets_left)\n",
    "right_psd_logs_all = combine_datasets(datasets_right)\n",
    "\n",
    "# Export to csv\n",
    "middle_psd_logs_all.to_csv('featured_data/Middle_PSDLogs.csv', index=False)\n",
    "left_psd_logs_all.to_csv('featured_data/Left_PSDLogs.csv', index=False)\n",
    "right_psd_logs_all.to_csv('featured_data/Right_PSDLogs.csv', index=False)\n",
    "\n",
    "# Drop any row with a NaN\n",
    "middle_psd_logs_all = middle_feats_all.dropna()\n",
    "left_psd_logs_all = left_feats_all.dropna()\n",
    "right_psd_logs_all = right_feats_all.dropna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
